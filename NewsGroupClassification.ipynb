{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae55b2de",
   "metadata": {},
   "source": [
    "# Loading Data ( News ) From the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8be3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:49...\n",
       "1        Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...\n",
       "2        Newsgroups: alt.atheism\\nPath: cantaloupe.srv....\n",
       "3        Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...\n",
       "4        Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...\n",
       "                               ...                        \n",
       "19992    Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:54...\n",
       "19993    Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:54...\n",
       "19994    Xref: cantaloupe.srv.cs.cmu.edu talk.religion....\n",
       "19995    Xref: cantaloupe.srv.cs.cmu.edu talk.religion....\n",
       "19996    Xref: cantaloupe.srv.cs.cmu.edu talk.abortion:...\n",
       "Name: News, Length: 19997, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "Base_Folder = r'D:\\Materials\\6th Semester\\Natural Language Processing\\Project\\20_newsgroups'\n",
    "\n",
    "Groups = [\n",
    "    'alt.atheism',\n",
    "    'comp.graphics',\n",
    "    'comp.os.ms-windows.misc',\n",
    "    'comp.sys.ibm.pc.hardware',\n",
    "    'comp.sys.mac.hardware',\n",
    "    'comp.windows.x',\n",
    "    'misc.forsale',\n",
    "    'rec.autos',\n",
    "    'rec.motorcycles',\n",
    "    'rec.sport.baseball',\n",
    "    'rec.sport.hockey',\n",
    "    'sci.crypt',\n",
    "    'sci.electronics',\n",
    "    'sci.med',\n",
    "    'sci.space',\n",
    "    'soc.religion.christian',\n",
    "    'talk.politics.guns',\n",
    "    'talk.politics.mideast',\n",
    "    'talk.politics.misc',\n",
    "    'talk.religion.misc'\n",
    "]\n",
    "\n",
    "All_News = []\n",
    "Targets = []\n",
    "for Group in Groups:\n",
    "    CurFolder = Base_Folder + '\\\\' + Group\n",
    "    CurListOfFiles = os.listdir(CurFolder)\n",
    "    for file in CurListOfFiles:\n",
    "        PATH = CurFolder + '\\\\' + file\n",
    "        with open(PATH) as f:\n",
    "            News = f.read()\n",
    "            All_News.append(News)\n",
    "            Targets.append(Group)\n",
    "\n",
    "mydict = {'News':All_News ,'Group': Targets}\n",
    "\n",
    "News_DF = pd.DataFrame(mydict)\n",
    "\n",
    "X = News_DF['News']\n",
    "y = News_DF['Group']\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0102ea3",
   "metadata": {},
   "source": [
    "# Stop Words & Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b37294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Xref  cantaloupesrvcscmuedu altatheism altathe...\n",
       "1        Xref  cantaloupesrvcscmuedu altatheism altathe...\n",
       "2        Newsgroups  altatheism Path  cantaloupesrvcscm...\n",
       "3        Xref  cantaloupesrvcscmuedu altatheism altpoli...\n",
       "4        Xref  cantaloupesrvcscmuedu altatheism socmots...\n",
       "                               ...                        \n",
       "19992    Xref  cantaloupesrvcscmuedu altatheism talkrel...\n",
       "19993    Xref  cantaloupesrvcscmuedu altatheism talkrel...\n",
       "19994    Xref  cantaloupesrvcscmuedu talkreligionmisc t...\n",
       "19995    Xref  cantaloupesrvcscmuedu talkreligionmisc t...\n",
       "19996    Xref  cantaloupesrvcscmuedu talkabortion altat...\n",
       "Length: 19997, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# remove stopwords \n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "predoc_x= []\n",
    "for doc in X:\n",
    "    words = word_tokenize(doc)\n",
    "    predoc = [word for word in words if word.casefold() not in stop_words]\n",
    "    predoc_x.append(' '.join(predoc))\n",
    "\n",
    "X = pd.Series(predoc_x)\n",
    "\n",
    "#remove punctuation and any unnecessary char \n",
    "import re\n",
    "import string\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "for i in range(len(X)):\n",
    "    doc = X[i]\n",
    "    doc = re.sub(r'\\d+', '', doc)\n",
    "    doc = doc.translate(translator)\n",
    "    X[i] = doc\n",
    "\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49938a84",
   "metadata": {},
   "source": [
    "# Lemmatizing & Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00194365",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        xref cantaloupesrvcscmuedu altath altatheismmo...\n",
       "1        xref cantaloupesrvcscmuedu altath altatheismmo...\n",
       "2        newsgroup altath path cantaloupesrvcscmuedu cr...\n",
       "3        xref cantaloupesrvcscmuedu altath altpoliticsu...\n",
       "4        xref cantaloupesrvcscmuedu altath socmotss rec...\n",
       "                               ...                        \n",
       "19992    xref cantaloupesrvcscmuedu altath talkreligion...\n",
       "19993    xref cantaloupesrvcscmuedu altath talkreligion...\n",
       "19994    xref cantaloupesrvcscmuedu talkreligionmisc ta...\n",
       "19995    xref cantaloupesrvcscmuedu talkreligionmisc ta...\n",
       "19996    xref cantaloupesrvcscmuedu talkabort altath ta...\n",
       "Length: 19997, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "\n",
    "lemma_X= []\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "for doc in X:\n",
    "    words = word_tokenize(doc)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    lemma_X.append(' '.join(lemmatized_words))\n",
    "                \n",
    "X = pd.Series(lemma_X)\n",
    "\n",
    "stemmed_X = []\n",
    "stemmer = PorterStemmer() \n",
    "for doc in X:\n",
    "    words = word_tokenize(doc)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    stemmed_X.append(' '.join(stemmed_words))\n",
    "                \n",
    "X = pd.Series(stemmed_X)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    doc = X[i]\n",
    "    doc = re.sub(r'\\b\\w{1,2}\\b', '', doc) \n",
    "    X[i] = doc\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db7b25",
   "metadata": {},
   "source": [
    "# Target ( Groups ) Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05dfb374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "\n",
    "Encoder = preprocessing.LabelEncoder()\n",
    "y = Encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8befcd",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32194d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09546dc3",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2e2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization using TF_IDF \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "vectorizer.fit(X)\n",
    "X_train_tfidf =  vectorizer.transform(X_train)\n",
    "X_test_tfidf =  vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62bafe7",
   "metadata": {},
   "source": [
    "# Models training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a47bdd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, X_train_tfidf, y_train, X_test_tfidf, y_test):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(X_train_tfidf, y_train)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(X_test_tfidf)\n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd88fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy:  0.90025\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(alpha=1.6), X_train_tfidf, y_train, X_test_tfidf,y_test)\n",
    "print (\"Naive Bayes Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb57461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:  0.94975\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "accuracy = train_model(linear_model.LogisticRegression(), X_train_tfidf, y_train, X_test_tfidf,y_test)\n",
    "print (\"Logistic Regression Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2fbb3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy:  0.951\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "accuracy = train_model(svm.SVC(kernel='linear'), X_train_tfidf, y_train, X_test_tfidf,y_test)\n",
    "print (\"SVM Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
